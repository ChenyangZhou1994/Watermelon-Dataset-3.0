{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "逻辑回归(Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.导入相应的包"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "\n",
    "#visualizations\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.读取数据文件CSV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "    色泽  根蒂  敲声  纹理  脐部  触感     密度    含糖率 好瓜\n编号                                         \n1   青绿  蜷缩  浊响  清晰  凹陷  硬滑  0.697  0.460  是\n2   乌黑  蜷缩  沉闷  清晰  凹陷  硬滑  0.774  0.376  是\n3   乌黑  蜷缩  浊响  清晰  凹陷  硬滑  0.634  0.264  是\n4   青绿  蜷缩  沉闷  清晰  凹陷  硬滑  0.608  0.318  是\n5   浅白  蜷缩  浊响  清晰  凹陷  硬滑  0.556  0.215  是\n6   青绿  稍蜷  浊响  清晰  稍凹  软粘  0.403  0.237  是\n7   乌黑  稍蜷  浊响  稍糊  稍凹  软粘  0.481  0.149  是\n8   乌黑  稍蜷  浊响  清晰  稍凹  硬滑  0.437  0.211  是\n9   乌黑  稍蜷  沉闷  稍糊  稍凹  硬滑  0.666  0.091  否\n10  青绿  硬挺  清脆  清晰  平坦  软粘  0.243  0.267  否\n11  浅白  硬挺  清脆  模糊  平坦  硬滑  0.245  0.057  否\n12  浅白  蜷缩  浊响  模糊  平坦  软粘  0.343  0.099  否\n13  青绿  稍蜷  浊响  稍糊  凹陷  硬滑  0.639  0.161  否\n14  浅白  稍蜷  沉闷  稍糊  凹陷  硬滑  0.657  0.198  否\n15  乌黑  稍蜷  浊响  清晰  稍凹  软粘  0.360  0.370  否\n16  浅白  蜷缩  浊响  模糊  平坦  硬滑  0.593  0.042  否\n17  青绿  蜷缩  沉闷  稍糊  稍凹  硬滑  0.719  0.103  否",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>色泽</th>\n      <th>根蒂</th>\n      <th>敲声</th>\n      <th>纹理</th>\n      <th>脐部</th>\n      <th>触感</th>\n      <th>密度</th>\n      <th>含糖率</th>\n      <th>好瓜</th>\n    </tr>\n    <tr>\n      <th>编号</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>青绿</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.697</td>\n      <td>0.460</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>乌黑</td>\n      <td>蜷缩</td>\n      <td>沉闷</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.774</td>\n      <td>0.376</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>乌黑</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.634</td>\n      <td>0.264</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>青绿</td>\n      <td>蜷缩</td>\n      <td>沉闷</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.608</td>\n      <td>0.318</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>浅白</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.556</td>\n      <td>0.215</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>青绿</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>稍凹</td>\n      <td>软粘</td>\n      <td>0.403</td>\n      <td>0.237</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>稍糊</td>\n      <td>稍凹</td>\n      <td>软粘</td>\n      <td>0.481</td>\n      <td>0.149</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>稍凹</td>\n      <td>硬滑</td>\n      <td>0.437</td>\n      <td>0.211</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>沉闷</td>\n      <td>稍糊</td>\n      <td>稍凹</td>\n      <td>硬滑</td>\n      <td>0.666</td>\n      <td>0.091</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>青绿</td>\n      <td>硬挺</td>\n      <td>清脆</td>\n      <td>清晰</td>\n      <td>平坦</td>\n      <td>软粘</td>\n      <td>0.243</td>\n      <td>0.267</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>浅白</td>\n      <td>硬挺</td>\n      <td>清脆</td>\n      <td>模糊</td>\n      <td>平坦</td>\n      <td>硬滑</td>\n      <td>0.245</td>\n      <td>0.057</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>浅白</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>模糊</td>\n      <td>平坦</td>\n      <td>软粘</td>\n      <td>0.343</td>\n      <td>0.099</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>青绿</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>稍糊</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.639</td>\n      <td>0.161</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>浅白</td>\n      <td>稍蜷</td>\n      <td>沉闷</td>\n      <td>稍糊</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.657</td>\n      <td>0.198</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>稍凹</td>\n      <td>软粘</td>\n      <td>0.360</td>\n      <td>0.370</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>浅白</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>模糊</td>\n      <td>平坦</td>\n      <td>硬滑</td>\n      <td>0.593</td>\n      <td>0.042</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>青绿</td>\n      <td>蜷缩</td>\n      <td>沉闷</td>\n      <td>稍糊</td>\n      <td>稍凹</td>\n      <td>硬滑</td>\n      <td>0.719</td>\n      <td>0.103</td>\n      <td>否</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('watermelon_dataset3.csv', index_col=0)\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.EDA数据工程\n",
    "\n",
    "将数据分为字符串列、数字列和标签列，在对其进行操作，对于标签列进行转化，将是和否转化为0和1;\n",
    "数字列用于One-Hot编码，在对数值类型进行标准归一化。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 字符串列\n",
    "str_columns = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感']\n",
    "\n",
    "# 数字列\n",
    "num_columns = ['密度', '含糖率']\n",
    "\n",
    "#标签列\n",
    "label_columns = ['好瓜']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "       密度    含糖率  好瓜  色泽_乌黑  色泽_浅白  色泽_青绿  根蒂_硬挺  根蒂_稍蜷  根蒂_蜷缩  敲声_沉闷  敲声_浊响  \\\n编号                                                                             \n1   0.697  0.460   1      0      0      1      0      0      1      0      1   \n2   0.774  0.376   1      1      0      0      0      0      1      1      0   \n3   0.634  0.264   1      1      0      0      0      0      1      0      1   \n4   0.608  0.318   1      0      0      1      0      0      1      1      0   \n5   0.556  0.215   1      0      1      0      0      0      1      0      1   \n6   0.403  0.237   1      0      0      1      0      1      0      0      1   \n7   0.481  0.149   1      1      0      0      0      1      0      0      1   \n8   0.437  0.211   1      1      0      0      0      1      0      0      1   \n9   0.666  0.091   0      1      0      0      0      1      0      1      0   \n10  0.243  0.267   0      0      0      1      1      0      0      0      0   \n11  0.245  0.057   0      0      1      0      1      0      0      0      0   \n12  0.343  0.099   0      0      1      0      0      0      1      0      1   \n13  0.639  0.161   0      0      0      1      0      1      0      0      1   \n14  0.657  0.198   0      0      1      0      0      1      0      1      0   \n15  0.360  0.370   0      1      0      0      0      1      0      0      1   \n16  0.593  0.042   0      0      1      0      0      0      1      0      1   \n17  0.719  0.103   0      0      0      1      0      0      1      1      0   \n\n    敲声_清脆  纹理_模糊  纹理_清晰  纹理_稍糊  脐部_凹陷  脐部_平坦  脐部_稍凹  触感_硬滑  触感_软粘  \n编号                                                                 \n1       0      0      1      0      1      0      0      1      0  \n2       0      0      1      0      1      0      0      1      0  \n3       0      0      1      0      1      0      0      1      0  \n4       0      0      1      0      1      0      0      1      0  \n5       0      0      1      0      1      0      0      1      0  \n6       0      0      1      0      0      0      1      0      1  \n7       0      0      0      1      0      0      1      0      1  \n8       0      0      1      0      0      0      1      1      0  \n9       0      0      0      1      0      0      1      1      0  \n10      1      0      1      0      0      1      0      0      1  \n11      1      1      0      0      0      1      0      1      0  \n12      0      1      0      0      0      1      0      0      1  \n13      0      0      0      1      1      0      0      1      0  \n14      0      0      0      1      1      0      0      1      0  \n15      0      0      1      0      0      0      1      0      1  \n16      0      1      0      0      0      1      0      1      0  \n17      0      0      0      1      0      0      1      1      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>密度</th>\n      <th>含糖率</th>\n      <th>好瓜</th>\n      <th>色泽_乌黑</th>\n      <th>色泽_浅白</th>\n      <th>色泽_青绿</th>\n      <th>根蒂_硬挺</th>\n      <th>根蒂_稍蜷</th>\n      <th>根蒂_蜷缩</th>\n      <th>敲声_沉闷</th>\n      <th>敲声_浊响</th>\n      <th>敲声_清脆</th>\n      <th>纹理_模糊</th>\n      <th>纹理_清晰</th>\n      <th>纹理_稍糊</th>\n      <th>脐部_凹陷</th>\n      <th>脐部_平坦</th>\n      <th>脐部_稍凹</th>\n      <th>触感_硬滑</th>\n      <th>触感_软粘</th>\n    </tr>\n    <tr>\n      <th>编号</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.697</td>\n      <td>0.460</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.774</td>\n      <td>0.376</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.634</td>\n      <td>0.264</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.608</td>\n      <td>0.318</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.556</td>\n      <td>0.215</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.403</td>\n      <td>0.237</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.481</td>\n      <td>0.149</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.437</td>\n      <td>0.211</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.666</td>\n      <td>0.091</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.243</td>\n      <td>0.267</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.245</td>\n      <td>0.057</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.343</td>\n      <td>0.099</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.639</td>\n      <td>0.161</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.657</td>\n      <td>0.198</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.360</td>\n      <td>0.370</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.593</td>\n      <td>0.042</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.719</td>\n      <td>0.103</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将标签列进行转化，是否转化为0和1\n",
    "for i in tqdm(label_columns):\n",
    "    lbl = LabelEncoder()\n",
    "    df[i] = lbl.fit_transform(df[i].astype(str))\n",
    "\n",
    "# 将其他列进行One-hot编码\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "          密度       含糖率  好瓜  色泽_乌黑  色泽_浅白  色泽_青绿  根蒂_硬挺  根蒂_稍蜷  根蒂_蜷缩  敲声_沉闷  \\\n编号                                                                            \n1   1.015011  2.125346   1      0      0      1      0      0      1      0   \n2   1.490548  1.403072   1      1      0      0      0      0      1      1   \n3   0.625936  0.440041   1      1      0      0      0      0      1      0   \n4   0.465365  0.904359   1      0      0      1      0      0      1      1   \n5   0.144223  0.018714   1      0      1      0      0      0      1      0   \n6  -0.800675  0.207881   1      0      0      1      0      1      0      0   \n7  -0.318962 -0.548786   1      1      0      0      0      1      0      0   \n8  -0.590697 -0.015680   1      1      0      0      0      1      0      0   \n9   0.823562 -1.047499   0      1      0      0      0      1      0      1   \n10 -1.788803  0.465836   0      0      0      1      1      0      0      0   \n11 -1.776452 -1.339848   0      0      1      0      1      0      0      0   \n12 -1.171223 -0.978711   0      0      1      0      0      0      1      0   \n13  0.656815 -0.445604   0      0      0      1      0      1      0      0   \n14  0.767979 -0.127460   0      0      1      0      0      1      0      1   \n15 -1.066234  1.351481   0      1      0      0      0      1      0      0   \n16  0.372728 -1.468825   0      0      1      0      0      0      1      0   \n17  1.150879 -0.944317   0      0      0      1      0      0      1      1   \n\n    敲声_浊响  敲声_清脆  纹理_模糊  纹理_清晰  纹理_稍糊  脐部_凹陷  脐部_平坦  脐部_稍凹  触感_硬滑  触感_软粘  \n编号                                                                        \n1       1      0      0      1      0      1      0      0      1      0  \n2       0      0      0      1      0      1      0      0      1      0  \n3       1      0      0      1      0      1      0      0      1      0  \n4       0      0      0      1      0      1      0      0      1      0  \n5       1      0      0      1      0      1      0      0      1      0  \n6       1      0      0      1      0      0      0      1      0      1  \n7       1      0      0      0      1      0      0      1      0      1  \n8       1      0      0      1      0      0      0      1      1      0  \n9       0      0      0      0      1      0      0      1      1      0  \n10      0      1      0      1      0      0      1      0      0      1  \n11      0      1      1      0      0      0      1      0      1      0  \n12      1      0      1      0      0      0      1      0      0      1  \n13      1      0      0      0      1      1      0      0      1      0  \n14      0      0      0      0      1      1      0      0      1      0  \n15      1      0      0      1      0      0      0      1      0      1  \n16      1      0      1      0      0      0      1      0      1      0  \n17      0      0      0      0      1      0      0      1      1      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>密度</th>\n      <th>含糖率</th>\n      <th>好瓜</th>\n      <th>色泽_乌黑</th>\n      <th>色泽_浅白</th>\n      <th>色泽_青绿</th>\n      <th>根蒂_硬挺</th>\n      <th>根蒂_稍蜷</th>\n      <th>根蒂_蜷缩</th>\n      <th>敲声_沉闷</th>\n      <th>敲声_浊响</th>\n      <th>敲声_清脆</th>\n      <th>纹理_模糊</th>\n      <th>纹理_清晰</th>\n      <th>纹理_稍糊</th>\n      <th>脐部_凹陷</th>\n      <th>脐部_平坦</th>\n      <th>脐部_稍凹</th>\n      <th>触感_硬滑</th>\n      <th>触感_软粘</th>\n    </tr>\n    <tr>\n      <th>编号</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1.015011</td>\n      <td>2.125346</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.490548</td>\n      <td>1.403072</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.625936</td>\n      <td>0.440041</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.465365</td>\n      <td>0.904359</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.144223</td>\n      <td>0.018714</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-0.800675</td>\n      <td>0.207881</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-0.318962</td>\n      <td>-0.548786</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-0.590697</td>\n      <td>-0.015680</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.823562</td>\n      <td>-1.047499</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>-1.788803</td>\n      <td>0.465836</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>-1.776452</td>\n      <td>-1.339848</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>-1.171223</td>\n      <td>-0.978711</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.656815</td>\n      <td>-0.445604</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.767979</td>\n      <td>-0.127460</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>-1.066234</td>\n      <td>1.351481</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.372728</td>\n      <td>-1.468825</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1.150879</td>\n      <td>-0.944317</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对数值列进行标准归一化\n",
    "df[num_columns] = StandardScaler().fit_transform(df[num_columns])\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "all_columns = [i for i in df.columns if i not in ['编号','好瓜']]\n",
    "\n",
    "# 获取X 特征矩阵向量\n",
    "X = df[all_columns].values\n",
    "\n",
    "# 获取y 标签向量\n",
    "y = df[label_columns].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. 进行网格搜索找最优的参数\n",
    "- 需要调优的参数\n",
    "- 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）\n",
    "- tuned_parameters = {'penalty':['l1','l2'],\n",
    "                  'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "                   }\n",
    "- L1和L2正则化"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\82115\\.conda\\envs\\python36\\lib\\site-packages\\numpy\\core\\_asarray.py:83: UserWarning: Warning: converting a masked element to nan.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_penalty', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])\n",
      "-0.6597904694167614\n",
      "{'C': 0.1, 'penalty': 'l2'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#需要调优的参数\n",
    "# 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）\n",
    "#tuned_parameters = {'penalty':['l1','l2'],\n",
    "#                   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#                   }\n",
    "#L1和L2正则化\n",
    "penaltys = ['l1','l2']\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "tuned_parameters = dict(penalty = penaltys, C = Cs)\n",
    "#LR模型声明\n",
    "lr_penalty= LogisticRegression()\n",
    "#网格搜索声明\n",
    "grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5, scoring='neg_log_loss')\n",
    "# 进行训练\n",
    "grid.fit(X, y)\n",
    "\n",
    "# 网格搜索的关键字\n",
    "print(grid.cv_results_.keys())\n",
    "\n",
    "# 最优得分\n",
    "print(grid.best_score_)\n",
    "# 最优参数\n",
    "print(grid.best_params_)\n",
    "\n",
    "\n",
    "# 绘制plot CV误差曲线\n",
    "test_means = grid.cv_results_[ 'mean_test_score' ]\n",
    "test_stds = grid.cv_results_[ 'std_test_score' ]\n",
    "\n",
    "\n",
    "\n",
    "# plot results\n",
    "n_Cs = len(Cs)\n",
    "number_penaltys = len(penaltys)\n",
    "test_scores = np.array(test_means).reshape(n_Cs,number_penaltys)\n",
    "test_stds = np.array(test_stds).reshape(n_Cs,number_penaltys)\n",
    "\n",
    "x_axis = np.log10(Cs)\n",
    "for i, value in enumerate(penaltys):\n",
    "    #pyplot.plot(log(Cs), test_scores[i], label= 'penalty:'   + str(value))\n",
    "    plt.errorbar(x_axis, test_scores[:,i], yerr=test_stds[:,i] ,label = penaltys[i] +' Test')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel( 'log(C)' )\n",
    "plt.ylabel( 'neg-logloss' )\n",
    "plt.savefig('LogisticGridSearchCV_C.svg' )\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-1afc687d",
   "language": "python",
   "display_name": "PyCharm (DiseasePrediction)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}